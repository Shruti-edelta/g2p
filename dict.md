, ['Z', 'IH', 'L', 'AH'], ['Z', 'IH', 'L', 'K', 'AH'], ['Z', 'IH', 'L', 'S', 'T', 'R', 'AH'], ['Z', 'AY', 'M', 'AH', 'N'], ['Z', 'IH', 'N', 'D', 'AH'], ['Z', 'AY', 'S', 'K'], ['Z', 'IH', 'S', 'K', 'AO', 'F', 'S', 'K', 'IY'], ['Z', 'Y', 'UW', 'G', 'AA', 'N', 'AA', 'V'], ['Z', 'IH', 'W', 'IH', 'K', 'IY']]

,['i', 'n', 'd', 'u', 'b', 'i', 'o', 'u', 's', 'l', 'y'], ['i', 'n', 'd', 'u', 'c', 'e'], ['i', 'n', 'd', 'u', 'c', 'e', 'd'], ['i', 'n', 'd', 'u', 'c', 'e', 'm', 'e', 'n', 't'], ['i', 'n', 'd', 'u', 'c', 'e', 'm', 'e', 'n', 't', 's'], ['i', 'n', 'd', 'u', 'c', 'e', 's'], ['i', 'n', 'd', 'u', 'c', 'i', 'n', 'g'], ['i', 'n', 'd', 'u', 'c', 't'], ['i', 'n', 'd', 'u', 'c', 't', 'a', 'n', 'c', 'e'], ['i', 'n', 'd', 'u', 'c', 't', 'e', 'd'], ['i', 'n', 'd', 'u', 'c', 't', 'e', 'e'], ['i', 'n', 'd', 'u', 'c', 't', 'e', 'e', 's'], ['i', 'n', 'd', 'u', 'c', 't', 'i', 'o', 'n'], ['i', 'n', 'd', 'u', 'c', 't', 'o', 'r'], ['i', 'n', 'd', 'u', 'l', 'g', 'e'], ['i', 'n', 'd', 'u', 'l', 'g', 'e', 'd'], ['i', 'n', 'd', 'u', 'l', 'g', 'e', 'n', 'c', 'e'], ['i', 'n', 'd', 'u', 'l', 'g', 'e', 'n', 'c', 'e', 's']]

grapheme:  {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '<pad>': 0, '<sos>': 27, '<eos>': 28}


idx2phn: {1: 'AA', 2: 'AE', 3: 'AH', 4: 'AO', 5: 'AW', 6: 'AY', 7: 'B', 8: 'CH', 9: 'D', 10: 'DH', 11: 'EH', 12: 'ER', 13: 'EY', 14: 'F', 15: 'G', 16: 'HH', 17: 'IH', 18: 'IY', 19: 'JH', 20: 'K', 21: 'L', 22: 'M', 23: 'N', 24: 'NG', 25: 'OW', 26: 'OY', 27: 'P', 28: 'R', 29: 'S', 30: 'SH', 31: 'T', 32: 'TH', 33: 'UH', 34: 'UW', 35: 'V', 36: 'W', 37: 'Y', 38: 'Z', 39: 'ZH', 0: '<pad>', 40: '<sos>', 41: '<eos>'}
phoneme:  {'AA': 2, 'AE': 3, 'AH': 4, 'AO': 5, 'AW': 6, 'AY': 7, 'B': 8, 'CH': 9, 'D': 10, 'DH': 11, 'EH': 12, 'ER': 13, 'EY': 14, 'F': 15, 'G': 16, 'HH': 17, 'IH': 18, 'IY': 19, 'JH': 20, 'K': 21, 'L': 22, 'M': 23, 'N': 24, 'NG': 25, 'OW': 26, 'OY': 27, 'P': 28, 'R': 29, 'S': 30, 'SH': 31, 'T': 32, 'TH': 33, 'UH': 34, 'UW': 35, 'V': 36, 'W': 37, 'Y': 38, 'Z': 39, 'ZH': 40, '<pad>': 0, '<sos>': 40/1, '<eos>': 41}


Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ encoder_input (InputLayer)           │ (None, 33)                  │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ embedding (Embedding)                │ (None, 33, 128)             │           3,712 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv1d (Conv1D)                      │ (None, 33, 256)             │         164,096 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization                  │ (None, 33, 256)             │           1,024 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout (Dropout)                    │ (None, 33, 256)             │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv1d_1 (Conv1D)                    │ (None, 33, 256)             │         327,936 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization_1                │ (None, 33, 256)             │           1,024 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_1 (Dropout)                  │ (None, 33, 256)             │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv1d_2 (Conv1D)                    │ (None, 33, 256)             │         327,936 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization_2                │ (None, 33, 256)             │           1,024 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_2 (Dropout)                  │ (None, 33, 256)             │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv1d_3 (Conv1D)                    │ (None, 33, 256)             │         327,936 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization_3                │ (None, 33, 256)             │           1,024 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_3 (Dropout)                  │ (None, 33, 256)             │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ time_distributed (TimeDistributed)   │ (None, 33, 42)              │          10,794 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘            # 33 sample (input) 42 classes (output/phoneme)
 Total params: 1,166,506 (4.45 MB)
 Trainable params: 1,164,458 (4.44 MB)
 Non-trainable params: 2,048 (8.00 KB)
 Epoch 1/10
3250/3250 ━━━━━━━━━━━━━━━━━━━━ 244s 74ms/step - accuracy: 0.9044 - loss: 0.3369 - val_accuracy: 0.9477 - val_loss: 0.1667
Epoch 2/10
3250/3250 ━━━━━━━━━━━━━━━━━━━━ 247s 76ms/step - accuracy: 0.9525 - loss: 0.1450 - val_accuracy: 0.9558 - val_loss: 0.1413
Epoch 3/10
3250/3250 ━━━━━━━━━━━━━━━━━━━━ 237s 73ms/step - accuracy: 0.9593 - loss: 0.1230 - val_accuracy: 0.9595 - val_loss: 0.1287
Epoch 4/10
3250/3250 ━━━━━━━━━━━━━━━━━━━━ 238s 73ms/step - accuracy: 0.9633 - loss: 0.1111 - val_accuracy: 0.9619 - val_loss: 0.1232
Epoch 5/10
3250/3250 ━━━━━━━━━━━━━━━━━━━━ 237s 73ms/step - accuracy: 0.9657 - loss: 0.1025 - val_accuracy: 0.9619 - val_loss: 0.1197
Epoch 6/10
3250/3250 ━━━━━━━━━━━━━━━━━━━━ 237s 73ms/step - accuracy: 0.9672 - loss: 0.0973 - val_accuracy: 0.9605 - val_loss: 0.1237
Epoch 7/10
3250/3250 ━━━━━━━━━━━━━━━━━━━━ 240s 74ms/step - accuracy: 0.9688 - loss: 0.0926 - val_accuracy: 0.9609 - val_loss: 0.1242
Epoch 8/10
3250/3250 ━━━━━━━━━━━━━━━━━━━━ 237s 73ms/step - accuracy: 0.9700 - loss: 0.0889 - val_accuracy: 0.9613 - val_loss: 0.1233
Epoch 9/10
3250/3250 ━━━━━━━━━━━━━━━━━━━━ 247s 76ms/step - accuracy: 0.9711 - loss: 0.0846 - val_accuracy: 0.9629 - val_loss: 0.1207
Epoch 10/10
3250/3250 ━━━━━━━━━━━━━━━━━━━━ 244s 75ms/step - accuracy: 0.9717 - loss: 0.0831 - val_accuracy: 0.9622 - val_loss: 0.1204